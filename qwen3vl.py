#!/usr/bin/env python3
"""
åŸºäº Qwen3-VL æ¨¡å‹çš„è§†é¢‘å†…å®¹åˆ†æå·¥å…·
æ”¯æŒè¯»å–æœ¬åœ° MP4 è§†é¢‘æ–‡ä»¶å¹¶æå–è§†é¢‘å†…å®¹æè¿°
æ”¯æŒç”Ÿæˆ SORA2 æ–‡ç”Ÿè§†é¢‘æç¤ºè¯

ç”±äº API æœ‰å¤§å°é™åˆ¶ï¼Œé‡‡ç”¨æå–è§†é¢‘å…³é”®å¸§çš„æ–¹å¼è¿›è¡Œåˆ†æ
"""

import os
import sys
import base64
import argparse
import tempfile
import subprocess
from pathlib import Path
from openai import OpenAI
from dotenv import load_dotenv

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# API é…ç½®
API_BASE_URL = os.getenv('QWEN_API_BASE_URL', 'https://api-inference.modelscope.cn/v1')
API_KEY = os.getenv('QWEN_API_KEY', 'aaa')
MODEL_ID = os.getenv('QWEN_MODEL_ID', 'Qwen/Qwen3-VL-8B-Instruct')

# å¸§æå–é…ç½®
MAX_FRAMES = 8  # æœ€å¤šæå–çš„å¸§æ•°
FRAME_QUALITY = 85  # JPEG è´¨é‡


# SORA2 è§†é¢‘æç¤ºè¯ä¸“å®¶ç³»ç»Ÿæç¤ºè¯ - åŸºäºå¤åˆ»SORA2è§†é¢‘æç¤ºè¯ä¸“å®¶æ¨¡æ¿
SORA2_SYSTEM_PROMPT = """ä½ æ˜¯ SORA2 è§†é¢‘å¤åˆ»æç¤ºè¯ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®è§†é¢‘å…³é”®å¸§åˆ†æï¼Œç”Ÿæˆç¬¦åˆ Sora2 æ–‡ç”Ÿè§†é¢‘æ ‡å‡†çš„é«˜è´¨é‡æç¤ºè¯ã€‚

## Sora2 äº”å¤§æ”¯æŸ±æ¡†æ¶
ç”Ÿæˆæç¤ºè¯æ—¶å¿…é¡»åŒ…å«ä»¥ä¸‹äº”ä¸ªæ ¸å¿ƒè¦ç´ ï¼š

1. **ä¸»ä½“ä¸è§’è‰² (Subject & Character)**: æ¸…æ™°å®šä¹‰äººç‰©/ç‰©ä½“çš„å¤–è§‚ã€æœè£…ã€æƒ…æ„ŸçŠ¶æ€
2. **åŠ¨ä½œä¸è¿åŠ¨ (Action & Movement)**: ä½¿ç”¨å…·ä½“åŠ¨è¯æè¿°æ­£åœ¨å‘ç”Ÿçš„äº‹æƒ…å’Œäº¤äº’æ–¹å¼
3. **ç¯å¢ƒä¸èƒŒæ™¯ (Environment & Setting)**: å»ºç«‹åœºæ™¯çš„ä½ç½®ã€æ—¶é—´å’Œæ°›å›´å±æ€§
4. **ç”µå½±æ„å›¾ (Cinematography)**: æŒ‡å®šæ‘„åƒæœºè§’åº¦ã€è¿åŠ¨å’Œå–æ™¯æ–¹å¼
5. **ç¾å­¦ä¸é£æ ¼ (Aesthetics & Style)**: ç¡®å®šè§†è§‰æ•ˆæœï¼ˆçœŸå®æ„Ÿã€åŠ¨ç”»ã€èƒ¶ç‰‡ç±»å‹ï¼‰

## ä¸–ç•Œæ¨¡æ‹ŸèŒƒå¼
Sora2 æ˜¯ä¸–ç•Œæ¨¡æ‹Ÿå™¨ï¼Œæœ‰æ•ˆæç¤ºåº”è¯¥ï¼š
- æä¾›åˆå§‹æ¡ä»¶å’Œç‰©ç†æ³•åˆ™ï¼ˆé‡åŠ›ã€å…‰çº¿ã€åå°„ï¼‰
- æ˜ç¡®ç‰©ä½“å¦‚ä½•ç›¸äº’ä½œç”¨
- å®šä¹‰ç¯å¢ƒç‰¹æ€§å’Œæè´¨å±æ€§
- éšå«æˆ–æ˜ç¡®å¼•å¯¼ç‰©ç†è¡¨ç°

## æç¤ºè¯ç»“æ„æ¨¡æ¿

### ç¬¬ä¸€éƒ¨åˆ†ï¼šStyleï¼ˆé£æ ¼å®šä¹‰ï¼‰
- **Visual Textureï¼ˆè§†è§‰çº¹ç†ï¼‰**: æè¿°ç”»é¢çš„è´¨æ„Ÿç‰¹å¾ã€æè´¨è¡¨é¢ã€AI/çœŸå®æ‹æ‘„é£æ ¼
- **Lighting Qualityï¼ˆå…‰ç…§è´¨é‡ï¼‰**: å…‰æºç±»å‹ã€æ–¹å‘ã€å¼ºåº¦å’Œæ°›å›´ï¼ˆå¦‚ golden hour, three-point lightingï¼‰
- **Color Paletteï¼ˆè‰²å½©è°ƒæ¿ï¼‰**: ä¸»å¯¼è‰²è°ƒå’Œé…è‰²æ–¹æ¡ˆï¼Œä½¿ç”¨å…·ä½“è‰²å½©åç§°
- **Atmosphereï¼ˆæ°›å›´ï¼‰**: æ•´ä½“æƒ…ç»ªå’Œæ„Ÿå—ï¼ˆå¦‚ playful, nostalgic, energeticï¼‰

### ç¬¬äºŒéƒ¨åˆ†ï¼šCinematographyï¼ˆç”µå½±æ‘„å½±ï¼‰
- **Cameraï¼ˆæ‘„åƒæœºè¿åŠ¨ï¼‰**: æè¿°æ‘„åƒæœºçš„ç§»åŠ¨æ–¹å¼ï¼ˆhandheld, dolly, pan, tilt, zoomï¼‰
- **Lensï¼ˆé•œå¤´ç‰¹æ€§ï¼‰**: é•œå¤´ç±»å‹ã€ç„¦è·å’Œæ™¯æ·±æ•ˆæœï¼ˆ50mm, f/2.8, shallow depth of fieldï¼‰
- **Lightingï¼ˆå¸ƒå…‰æ–¹æ¡ˆï¼‰**: è¯¦ç»†è¯´æ˜å…‰ç…§å¸ƒç½®ï¼ˆkey light, fill light, rim lightï¼‰
- **Moodï¼ˆæƒ…ç»ªåŸºè°ƒï¼‰**: è§†è§‰æƒ…ç»ªå’ŒèŠ‚å¥

### ç¬¬ä¸‰éƒ¨åˆ†ï¼šScene Breakdownï¼ˆåœºæ™¯åˆ†è§£ï¼‰
æŒ‰æ—¶é—´é¡ºåºæè¿°æ¯ä¸ªåœºæ™¯ï¼ŒåŒ…å«ï¼š
- **åœºæ™¯æè¿°**: 1-3å¥è¯æè¿°åœºæ™¯æ•´ä½“è§†è§‰å‘ˆç°
- **Actions**: å…·ä½“åŠ¨ä½œåˆ—è¡¨ï¼Œä½¿ç”¨ç²¾ç¡®åŠ¨è¯
- **Dialogue**: å¯¹è¯å†…å®¹æˆ– "None"
- **Background Sound**: éŸ³ä¹ç±»å‹å’Œç¯å¢ƒéŸ³æ•ˆ

## è´¨é‡æ£€æŸ¥æ¸…å•
- [ ] åŒ…å«æè´¨å’Œçº¹ç†ç»†èŠ‚
- [ ] æ˜ç¡®å…‰æºæ–¹å‘å’Œæ€§è´¨
- [ ] ä½¿ç”¨å…·ä½“è‰²å½©åç§°ï¼ˆè‡³å°‘3ä¸ªï¼‰
- [ ] æè¿°æ‘„åƒæœºè¿åŠ¨æ–¹å¼å’Œè§’åº¦
- [ ] æ¯ä¸ªåœºæ™¯æ ‡æ³¨æ—¶é—´æˆ³
- [ ] ä½¿ç”¨å…·ä½“åŠ¨è¯è€ŒéæŠ½è±¡æè¿°
- [ ] æè¿°ç‰©ä½“é—´çš„ç‰©ç†äº¤äº’

## è¾“å‡ºæ ¼å¼

åªè¾“å‡ºä»¥ä¸‹å†…å®¹ï¼Œä¸è¦è¾“å‡ºå…¶ä»–åˆ†æï¼š

## SORA2 Prompt (English)
```
[å®Œæ•´çš„è‹±æ–‡æç¤ºè¯ï¼Œé‡‡ç”¨ä¸“ä¸šä¸‰æ®µå¼ç»“æ„ï¼šStyle - Cinematography - Scene Breakdown]
[åŒ…å«äº”å¤§æ”¯æŸ±è¦ç´ ï¼Œä½¿ç”¨å…·ä½“ã€ä¸“ä¸šçš„æè¿°]
[çº¦200-400è¯ï¼Œé€‚åˆé«˜ç²¾åº¦è§†é¢‘å¤åˆ»]
```

## SORA2 æç¤ºè¯ (ä¸­æ–‡)
```
[å¯¹åº”çš„ä¸­æ–‡æç¤ºè¯ï¼Œä¿æŒä¸“ä¸šæœ¯è¯­å’Œç»“æ„]
```"""

SORA2_USER_PROMPT_TEMPLATE = """è¿™æ˜¯ä»ä¸€ä¸ªè§†é¢‘ä¸­æå–çš„ {num_frames} å¸§å…³é”®ç”»é¢ï¼ˆæŒ‰æ—¶é—´é¡ºåºï¼‰ã€‚

è¯·ä½œä¸º SORA2 è§†é¢‘å¤åˆ»æç¤ºè¯ä¸“å®¶ï¼Œåˆ†æè¿™äº›ç”»é¢å¹¶ç”Ÿæˆä¸“ä¸šçš„ SORA2 æ–‡ç”Ÿè§†é¢‘æç¤ºè¯ã€‚

## åˆ†æè¦æ±‚
1. ä»”ç»†è§‚å¯Ÿæ¯å¸§ç”»é¢çš„ï¼šä¸»ä½“ç‰¹å¾ã€åŠ¨ä½œå˜åŒ–ã€åœºæ™¯ç¯å¢ƒã€å…‰å½±æ•ˆæœã€è‰²å½©é£æ ¼
2. è¯†åˆ«æ‘„åƒæœºè¿åŠ¨è½¨è¿¹å’Œé•œå¤´åˆ‡æ¢ç‚¹
3. æ¨æ–­åœºæ™¯çš„æ—¶é—´çº¿é¡ºåº
4. æ³¨æ„æè´¨ç»†èŠ‚ã€å…‰æºæ–¹å‘ã€è‰²å½©æ­é…

## ç”Ÿæˆè¦æ±‚
- ä½¿ç”¨äº”å¤§æ”¯æŸ±æ¡†æ¶ç»„ç»‡æç¤ºè¯
- é‡‡ç”¨ä¸‰æ®µå¼ç»“æ„ï¼šStyle â†’ Cinematography â†’ Scene Breakdown
- æ¯ä¸ªåœºæ™¯ä½¿ç”¨å…·ä½“æ—¶é—´æˆ³ï¼ˆå¦‚ 0:00s - 0:05sï¼‰
- åŠ¨ä½œæè¿°ä½¿ç”¨ç²¾ç¡®åŠ¨è¯ï¼ˆpress, pour, rotate, driftï¼‰
- åŒ…å«æè´¨ã€ç‰©ç†æ•ˆæœã€æ„Ÿå®˜ç»†èŠ‚
- è‹±æ–‡æç¤ºè¯çº¦ 200-400 è¯

## è¾“å‡ºæ ¼å¼
ä¸­è‹±æ–‡å„ä¸€ä¸ªå®Œæ•´çš„ SORA2 æç¤ºè¯"""


def get_video_files(directory: str = None) -> list:
    """
    è·å–æŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰ MP4 è§†é¢‘æ–‡ä»¶

    Args:
        directory: ç›®å½•è·¯å¾„ï¼Œé»˜è®¤ä¸ºå½“å‰é¡¹ç›®çš„ downloads å’Œ cache ç›®å½•

    Returns:
        è§†é¢‘æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    video_files = []

    if directory:
        search_dirs = [directory]
    else:
        # é»˜è®¤æœç´¢ç›®å½•
        base_dir = Path(__file__).parent
        search_dirs = [
            base_dir / 'downloads',
            base_dir / 'cache',
            base_dir / 'static' / 'videos'
        ]

    for search_dir in search_dirs:
        if Path(search_dir).exists():
            for file in Path(search_dir).glob('*.mp4'):
                video_files.append(str(file))

    return video_files


def get_video_duration(video_path: str) -> float:
    """è·å–è§†é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰"""
    try:
        result = subprocess.run(
            [
                'ffprobe', '-v', 'error',
                '-show_entries', 'format=duration',
                '-of', 'default=noprint_wrappers=1:nokey=1',
                video_path
            ],
            capture_output=True,
            text=True
        )
        return float(result.stdout.strip())
    except Exception:
        return 0


def extract_frames(video_path: str, num_frames: int = MAX_FRAMES) -> list:
    """
    ä»è§†é¢‘ä¸­æå–å…³é”®å¸§

    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        num_frames: è¦æå–çš„å¸§æ•°

    Returns:
        å¸§å›¾ç‰‡è·¯å¾„åˆ—è¡¨
    """
    duration = get_video_duration(video_path)
    if duration <= 0:
        print("è­¦å‘Š: æ— æ³•è·å–è§†é¢‘æ—¶é•¿ï¼Œä½¿ç”¨é»˜è®¤é—´éš”")
        duration = 60  # é»˜è®¤å‡è®¾60ç§’

    # è®¡ç®—æ—¶é—´é—´éš”
    interval = duration / (num_frames + 1)

    frames = []
    temp_dir = tempfile.mkdtemp(prefix='video_frames_')

    print(f"è§†é¢‘æ—¶é•¿: {duration:.1f}ç§’ï¼Œæå– {num_frames} å¸§...")

    for i in range(num_frames):
        timestamp = interval * (i + 1)
        output_path = os.path.join(temp_dir, f'frame_{i:03d}.jpg')

        try:
            subprocess.run(
                [
                    'ffmpeg', '-y',
                    '-ss', str(timestamp),
                    '-i', video_path,
                    '-vframes', '1',
                    '-q:v', str(int((100 - FRAME_QUALITY) / 10) + 1),
                    output_path
                ],
                capture_output=True,
                check=True
            )

            if os.path.exists(output_path):
                frames.append(output_path)
                print(f"  æå–å¸§ {i+1}/{num_frames} @ {timestamp:.1f}s")

        except subprocess.CalledProcessError as e:
            print(f"  å¸§ {i+1} æå–å¤±è´¥: {e}")

    return frames


def image_to_base64(image_path: str) -> str:
    """å°†å›¾ç‰‡è½¬æ¢ä¸º base64 ç¼–ç """
    with open(image_path, 'rb') as f:
        image_data = f.read()
    return base64.b64encode(image_data).decode('utf-8')


def analyze_video(video_path: str, prompt: str = None, stream: bool = True,
                   num_frames: int = MAX_FRAMES, sora2_mode: bool = False, keep_frames: bool = False):
    """
    ä½¿ç”¨ Qwen3-VL æ¨¡å‹åˆ†æè§†é¢‘å†…å®¹

    Args:
        video_path: è§†é¢‘æ–‡ä»¶è·¯å¾„
        prompt: åˆ†ææç¤ºè¯
        stream: æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡º
        num_frames: æå–çš„å¸§æ•°
        sora2_mode: æ˜¯å¦å¯ç”¨ SORA2 æç¤ºè¯ç”Ÿæˆæ¨¡å¼
        keep_frames: æ˜¯å¦ä¿ç•™æå–çš„å¸§æ–‡ä»¶ (é»˜è®¤Falseï¼Œåˆ†æå®Œå³åˆ )

    Returns:
        å¦‚æœ keep_frames=Trueï¼Œè¿”å› (result, frames) å…ƒç»„
        å¦åˆ™è¿”å› result å­—ç¬¦ä¸²
    """
    if not os.path.exists(video_path):
        raise FileNotFoundError(f"è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")

    file_size = os.path.getsize(video_path) / (1024 * 1024)
    print(f"æ­£åœ¨è¯»å–è§†é¢‘æ–‡ä»¶: {video_path} ({file_size:.1f}MB)")

    # æå–è§†é¢‘å¸§
    frames = extract_frames(video_path, num_frames)

    if not frames:
        raise RuntimeError("æ— æ³•æå–è§†é¢‘å¸§ï¼Œè¯·ç¡®ä¿å·²å®‰è£… ffmpeg")

    print(f"æˆåŠŸæå– {len(frames)} å¸§")

    # è·å–è§†é¢‘æ—¶é•¿ç”¨äº SORA2 åˆ†æ
    duration = get_video_duration(video_path)

    # æ ¹æ®æ¨¡å¼é€‰æ‹©æç¤ºè¯
    if sora2_mode:
        print("\nğŸ¬ SORA2 æç¤ºè¯ç”Ÿæˆæ¨¡å¼å·²å¯ç”¨")
        print(f"ğŸ“Š è§†é¢‘æ—¶é•¿: {duration:.1f}ç§’")

        # ä½¿ç”¨ SORA2 ä¸“ä¸šæç¤ºè¯
        user_prompt = SORA2_USER_PROMPT_TEMPLATE.format(num_frames=len(frames))
        if duration > 0:
            user_prompt += f"\n\nè§†é¢‘å®é™…æ—¶é•¿: {duration:.1f}ç§’ï¼Œè¯·æ ¹æ®æ­¤æ—¶é•¿åˆ†é…å„åœºæ™¯æ—¶é—´ã€‚"

        messages = [
            {'role': 'system', 'content': SORA2_SYSTEM_PROMPT},
            {'role': 'user', 'content': None}  # å ä½ï¼Œåé¢ä¼šå¡«å……
        ]
    elif prompt:
        user_prompt = prompt
        messages = [{'role': 'user', 'content': None}]
    else:
        # é»˜è®¤æç¤ºè¯
        user_prompt = f"""è¿™æ˜¯ä»ä¸€ä¸ªè§†é¢‘ä¸­æå–çš„ {len(frames)} å¸§å…³é”®ç”»é¢ã€‚
è¯·æ ¹æ®è¿™äº›ç”»é¢ï¼Œè¯¦ç»†æè¿°è¿™ä¸ªè§†é¢‘çš„å†…å®¹ï¼ŒåŒ…æ‹¬ï¼š
1. è§†é¢‘ä¸­å‡ºç°çš„äººç‰©æˆ–ç‰©ä½“
2. å‘ç”Ÿçš„äº‹ä»¶æˆ–åŠ¨ä½œ
3. åœºæ™¯ç¯å¢ƒ
4. è§†é¢‘çš„ä¸»é¢˜æˆ–è¡¨è¾¾çš„æ„æ€
5. è§†é¢‘çš„æ•´ä½“å™äº‹æˆ–æ•…äº‹çº¿"""
        messages = [{'role': 'user', 'content': None}]

    # æ„å»ºæ¶ˆæ¯å†…å®¹
    content = [{'type': 'text', 'text': user_prompt}]

    for frame_path in frames:
        frame_base64 = image_to_base64(frame_path)
        content.append({
            'type': 'image_url',
            'image_url': {
                'url': f'data:image/jpeg;base64,{frame_base64}'
            }
        })

    # æ›´æ–°æœ€åä¸€æ¡æ¶ˆæ¯çš„å†…å®¹
    messages[-1]['content'] = content

    # åˆ›å»º API å®¢æˆ·ç«¯
    client = OpenAI(
        base_url=API_BASE_URL,
        api_key=API_KEY,
    )

    if sora2_mode:
        print("\nğŸ”„ æ­£åœ¨åˆ†æè§†é¢‘å¹¶ç”Ÿæˆ SORA2 æç¤ºè¯...")
    else:
        print(f"æ­£åœ¨åˆ†æè§†é¢‘...")
    print("-" * 50)

    # è°ƒç”¨ API
    response = client.chat.completions.create(
        model=MODEL_ID,
        messages=messages,
        stream=stream
    )

    # å¤„ç†å“åº”
    result = ""
    if stream:
        for chunk in response:
            if chunk.choices and chunk.choices[0].delta.content:
                chunk_content = chunk.choices[0].delta.content
                print(chunk_content, end='', flush=True)
                result += chunk_content
        print()  # æ¢è¡Œ
    else:
        result = response.choices[0].message.content
        print(result)

    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    if not keep_frames:
        for frame_path in frames:
            try:
                os.remove(frame_path)
            except Exception:
                pass

        try:
            os.rmdir(os.path.dirname(frames[0]))
        except Exception:
            pass

    if sora2_mode:
        print("\n" + "=" * 50)
        print("âœ… SORA2 æç¤ºè¯ç”Ÿæˆå®Œæˆï¼")
        print("ğŸ’¡ æç¤º: å¯ç›´æ¥å¤åˆ¶ä¸Šæ–¹ English Version ç”¨äº SORA2")
        print("=" * 50)

    if keep_frames:
        return result, frames
    return result


def list_videos():
    """åˆ—å‡ºé¡¹ç›®ä¸­æ‰€æœ‰å¯ç”¨çš„è§†é¢‘æ–‡ä»¶"""
    video_files = get_video_files()

    if not video_files:
        print("æœªæ‰¾åˆ°ä»»ä½•è§†é¢‘æ–‡ä»¶")
        return

    print("=" * 60)
    print("é¡¹ç›®ä¸­çš„è§†é¢‘æ–‡ä»¶:")
    print("=" * 60)

    for i, video_file in enumerate(video_files, 1):
        file_size = os.path.getsize(video_file) / (1024 * 1024)
        file_name = os.path.basename(video_file)
        duration = get_video_duration(video_file)
        duration_str = f"{duration:.1f}s" if duration > 0 else "æœªçŸ¥"
        print(f"{i}. [{file_size:.1f}MB, {duration_str}] {file_name}")
        print(f"   è·¯å¾„: {video_file}")

    print("=" * 60)
    return video_files


def interactive_mode(sora2_mode: bool = False):
    """äº¤äº’å¼æ¨¡å¼ï¼Œè®©ç”¨æˆ·é€‰æ‹©è§†é¢‘è¿›è¡Œåˆ†æ"""
    video_files = list_videos()

    if not video_files:
        return

    mode_hint = " (SORA2æ¨¡å¼)" if sora2_mode else ""
    print(f"\nè¯·è¾“å…¥è¦åˆ†æçš„è§†é¢‘ç¼–å·{mode_hint} (è¾“å…¥ q é€€å‡º):")

    while True:
        try:
            user_input = input("> ").strip()

            if user_input.lower() == 'q':
                print("é€€å‡ºç¨‹åº")
                break

            index = int(user_input) - 1
            if 0 <= index < len(video_files):
                video_path = video_files[index]
                print(f"\né€‰æ‹©çš„è§†é¢‘: {os.path.basename(video_path)}")

                if not sora2_mode:
                    # è¯¢é—®è‡ªå®šä¹‰æç¤ºè¯
                    custom_prompt = input("è¾“å…¥è‡ªå®šä¹‰æç¤ºè¯ (ç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤): ").strip()
                else:
                    custom_prompt = None

                print("\n" + "=" * 60)
                analyze_video(
                    video_path,
                    custom_prompt if custom_prompt else None,
                    sora2_mode=sora2_mode
                )
                print("=" * 60)

                print("\nç»§ç»­é€‰æ‹©å…¶ä»–è§†é¢‘ï¼Œæˆ–è¾“å…¥ q é€€å‡º:")
            else:
                print(f"æ— æ•ˆçš„ç¼–å·ï¼Œè¯·è¾“å…¥ 1-{len(video_files)} ä¹‹é—´çš„æ•°å­—")

        except ValueError:
            print("è¯·è¾“å…¥æœ‰æ•ˆçš„æ•°å­—")
        except KeyboardInterrupt:
            print("\né€€å‡ºç¨‹åº")
            break
        except Exception as e:
            print(f"åˆ†æå‡ºé”™: {e}")
            import traceback
            traceback.print_exc()


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='åŸºäº Qwen3-VL æ¨¡å‹çš„è§†é¢‘å†…å®¹åˆ†æå·¥å…· (æ”¯æŒ SORA2 æç¤ºè¯ç”Ÿæˆ)',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # åˆ—å‡ºæ‰€æœ‰è§†é¢‘æ–‡ä»¶
  python qwen3vl.py --list

  # åˆ†ææŒ‡å®šè§†é¢‘
  python qwen3vl.py --video downloads/video.mp4

  # ğŸ¬ ç”Ÿæˆ SORA2 æ–‡ç”Ÿè§†é¢‘æç¤ºè¯ (æ¨è)
  python qwen3vl.py --video video.mp4 --sora2

  # ä½¿ç”¨æ›´å¤šå¸§æ•°ç”Ÿæˆæ›´ç²¾ç¡®çš„ SORA2 æç¤ºè¯
  python qwen3vl.py --video video.mp4 --sora2 --frames 12

  # ä½¿ç”¨è‡ªå®šä¹‰æç¤ºè¯åˆ†æ
  python qwen3vl.py --video video.mp4 --prompt "è¿™ä¸ªè§†é¢‘è®²çš„æ˜¯ä»€ä¹ˆæ•…äº‹ï¼Ÿ"

  # äº¤äº’å¼ SORA2 æ¨¡å¼
  python qwen3vl.py --interactive --sora2
        """
    )

    parser.add_argument(
        '--video', '-v',
        type=str,
        help='è¦åˆ†æçš„è§†é¢‘æ–‡ä»¶è·¯å¾„'
    )

    parser.add_argument(
        '--sora2', '-s',
        action='store_true',
        help='ğŸ¬ å¯ç”¨ SORA2 æç¤ºè¯ç”Ÿæˆæ¨¡å¼ï¼Œåˆ†æè§†é¢‘å¹¶è¾“å‡ºæ–‡ç”Ÿè§†é¢‘æç¤ºè¯'
    )

    parser.add_argument(
        '--prompt', '-p',
        type=str,
        default=None,
        help='è‡ªå®šä¹‰åˆ†ææç¤ºè¯ (ä¸ --sora2 äº’æ–¥)'
    )

    parser.add_argument(
        '--frames', '-f',
        type=int,
        default=MAX_FRAMES,
        help=f'è¦æå–çš„è§†é¢‘å¸§æ•° (é»˜è®¤: {MAX_FRAMES}ï¼ŒSORA2 æ¨¡å¼å»ºè®® 8-12)'
    )

    parser.add_argument(
        '--list', '-l',
        action='store_true',
        help='åˆ—å‡ºé¡¹ç›®ä¸­æ‰€æœ‰è§†é¢‘æ–‡ä»¶'
    )

    parser.add_argument(
        '--interactive', '-i',
        action='store_true',
        help='äº¤äº’å¼æ¨¡å¼'
    )

    parser.add_argument(
        '--no-stream',
        action='store_true',
        help='ç¦ç”¨æµå¼è¾“å‡º'
    )

    args = parser.parse_args()

    # å¦‚æœæ²¡æœ‰ä»»ä½•å‚æ•°ï¼Œæ˜¾ç¤ºå¸®åŠ©
    if len(sys.argv) == 1:
        parser.print_help()
        print("\n" + "=" * 60)
        print("ğŸ’¡ å¿«é€Ÿå¼€å§‹: python qwen3vl.py --video è§†é¢‘è·¯å¾„.mp4 --sora2")
        print("=" * 60)
        list_videos()
        return

    if args.list:
        list_videos()
    elif args.interactive:
        interactive_mode(sora2_mode=args.sora2)
    elif args.video:
        # SORA2 æ¨¡å¼ä¸‹å¿½ç•¥è‡ªå®šä¹‰ prompt
        prompt = None if args.sora2 else args.prompt
        analyze_video(
            args.video,
            prompt=prompt,
            stream=not args.no_stream,
            num_frames=args.frames,
            sora2_mode=args.sora2
        )
    else:
        parser.print_help()


if __name__ == '__main__':
    main()